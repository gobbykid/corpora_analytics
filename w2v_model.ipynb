{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec model for GOBBYKID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to display values representing words similarities, we first need to create some models to train with respect to our corpora. Such models will be ablo to use <i>word embeddings</i> in order to retrieve similarities between the words of each corpus. This will be accomplished thanks to the mapping of such words into of feature-vectors.</br>\n",
    "The aim of this section is to develop some different <i><u>word2vec</u></i> models, each with different parameters.</br>\n",
    "At the end of the training session, we will qualitatively decide which one performs better in the definition of word similarities and save such model (obviously, the models will be two for each try: one for the female authors corpus and the other one for the male authors corpus). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an overview of the libraries used in this project, you can check the [README file](README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once followed the instructions provided in the above mentioned file, you can import the libraries, as well as the functions defined in the [normalizations functions file](normalization_functions.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normalization_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen that the purpose of this project is the one defined in the [README file](README.md), we have obviously decided to train our model on the basis of the two corpora that we aim at analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a w2v model, we first need to create the two corpora for which we want to build the model, then we will store all the urls of the texts contained inside them into two different lists.</br>\n",
    "Such lists will be passed as input to a function developed to store all the tokens of a corpus inside a list. During this step, texts will also need some preprocessing operation that will be performed by the same <span style=\"color:#89FC00\"><i>list_builder</i></span> function, contained inside the [normalization functions file](normalization_functions.py), that will also create the two lists of which we were talking before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_directory = \"Raw/F/\"\n",
    "m_directory = \"Raw/M/\"\n",
    "f_corpus = create_corpus(f_directory)\n",
    "m_corpus = create_corpus(m_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female authors corpus\n",
    "f_authors_texts = list()\n",
    "for url in f_corpus.fileids():\n",
    "    if url != '.DS_Store':\n",
    "        f_authors_texts.append(f_directory+url)\n",
    "\n",
    "# Male authors corpus\n",
    "m_authors_texts = list()\n",
    "for url in m_corpus.fileids():\n",
    "    if url != '.DS_Store':\n",
    "        m_authors_texts.append(m_directory+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the urls extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLS of female authors texts: ['Raw/F/1839_sinclair-holiday-house-a-series-of-tales.txt', 'Raw/F/1841_martineau-the-settlers-at-home.txt', 'Raw/F/1857_browne-grannys-wonderful-chair.txt', 'Raw/F/1857_tucker-the-rambles-of-a-rat.txt', 'Raw/F/1862_ewing-melchiors-dream-and-other-tales.txt', 'Raw/F/1869_ewing-mrs-overtheways-remembrances.txt', 'Raw/F/1869_ewing-the-land-of-lost-toys.txt', 'Raw/F/1870_ewing-the-brownies-and-other-tales.txt', 'Raw/F/1872_craik-the-adventure-of-a-brownie.txt', 'Raw/F/1872_de-la-ramee-a-dog-of-flanders.txt', 'Raw/F/1873_ewing-a-flat-iron-for-a-farthing.txt', 'Raw/F/1875_craik-the-little-lame-prince-and-his-traveling-cloack.txt', 'Raw/F/1876_ewing-jan-of-the-windmill.txt', 'Raw/F/1876_ewing-six-to-sixteen-a-story-for-girls.txt', 'Raw/F/1877_ewing-a-great-emergency-and-other-tales.txt', 'Raw/F/1877_molesworth-the-cuckoo-clock.txt', 'Raw/F/1877_sewell-black-beauty.txt', 'Raw/F/1879_ewing-jackanapes-daddy-darwins-dovecot-and-other-stories.txt', 'Raw/F/1882_ewing-brothers-of-pity-and-other-tales-of-beasts-and-men.txt', 'Raw/F/1886_hodgson-burnett-little-lord-fauntleroy.txt', 'Raw/F/1887_molesworth-four-winds-farm.txt', 'Raw/F/1888_ewing-snap-dragons-old-father-christmas.txt', 'Raw/F/1899_nesbit-the-story-of-the-treasure-seekers.txt'] \n",
      "\n",
      "URLS of male authors texts: ['Raw/M/1841_marryat-masterman-ready.txt', 'Raw/M/1845_dickens-the-cricket-on-the-hearth-a-fairy-tale-of-home.txt', 'Raw/M/1847_marryat-the-children-of-the-new-forest.txt', 'Raw/M/1848_marryat-the-little-savage.txt', 'Raw/M/1851_ruskin-the-king-of-the-golden-river.txt', 'Raw/M/1857_ballantyne-the-coral-island-a-tale-of-the-pacific-ocean.txt', 'Raw/M/1857_hughes-tom-browns-school-days.txt', 'Raw/M/1862_farrar-st-winfreds-the-world-of-school.txt', 'Raw/M/1863_kingsley-the-water-babies.txt', 'Raw/M/1865_carroll-alices-adventures-in-wonderland.txt', 'Raw/M/1869_dickens-david-copperfield.txt', 'Raw/M/1870_hemyng-jack-harkaways-boy-tinker-among-the-turks.txt', 'Raw/M/1871_macdonald-at-the-back-of-the-north-wind.txt', 'Raw/M/1871_macdonald-ranald-bannermans-boyhood.txt', 'Raw/M/1872_macdonald-the-princess-and-the-goblin.txt', 'Raw/M/1873_macdonald-gutta-percha-willie-the-working-genius.txt', 'Raw/M/1875_macdonald-a-double-story.txt', 'Raw/M/1878_kingston-the-three-admirals.txt', 'Raw/M/1879_hemyng-jack-harkaway-in-new-york.txt', 'Raw/M/1879_hemyng-the-slave-of-the-mine.txt', 'Raw/M/1882_jefferies-bevis-the-story-of-a-boy.txt', 'Raw/M/1883_fenn-nat-the-naturalist-a-boys-adventures-in-the-eastern-seas.txt', 'Raw/M/1883_stevenson-treasure-island.txt', 'Raw/M/1888_macdonald-a-rough-shaking.txt', 'Raw/M/1888_wilde-the-happy-prince-and-other-tales.txt', 'Raw/M/1894_kipling-the-jungle-book.txt', 'Raw/M/1899_kipling-rewards-and-fairies.txt', 'Raw/M/190?_hemyng-jack-harkaway-and-his-sons-escape-from-the-brigands-of-greece.txt'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"URLS of female authors texts:\", f_authors_texts, '\\n')\n",
    "print(\"URLS of male authors texts:\", m_authors_texts, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we said above, we will go on by creating the two lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tokens = list_builder(f_authors_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tokens = list_builder(m_authors_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the two lists, we need to initialize the two different models thanks to the Gensim library.</br>\n",
    "Each model will be used for the respective corpus on which it has been trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end, we will create six groups of models and see which between these will perform better.</br>\n",
    "The parameters will be different for each group, and now we will provide a brief overiview of what we want to do.</br>\n",
    "In the word2vec model we may use 2 different methodologies to retrieve/produce word embeddings:\n",
    "- <span style=\"color:#EE6352\">CBOW (Continuous Bag Of Words)</span> - this first methodology operates by trying to solve a sort of \"fake problem\": given a context, the model tries to predict a target missing word. This is the base on which the model is trained in CBOW;\n",
    "- <span style=\"color:#EE6352\">Skip Grams</span> - the methodologies operates in an opposite way, in fact it tries to solve a similar problem but, this time, the input is the target word and the output will be its context.\n",
    "\n",
    "These are two different ways to train a word2vec model.</br></br>\n",
    "Together with these different ways to compute embeddings, we will try to change the <i>context-window size</i>, that is basically the amount of words that are part of the context we aim at analyzing (the size represents the amount of words on the left side and on the right side of the target word; e.g for a size of 3, the 3 words on the left and the 3 words on the right of a target word will be considered).</br>\n",
    "The different window sizes are computed after reading the article [Dependency-Based Word Embeddings](https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf), which states that <i>larger windows tend to capture more topic/domain information, while smaller windows tend to capture more information about the word itself</i>.</br>\n",
    "        To this end, we will produce three groups of models for each methodology, and these will have small window size, medium window size and large window size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F0A202\"><i>PAY ATTENTION: In order to use the \"workers\" parameter defined inside each w2v model object, you need first to install <b>Cython</b>. Such parameter operates by deciding how many core of the CPU will be used for operations concerning the model. If Cython is not installed, the model will use by default one single core, therefore the operations will take way too much time to be performed.</i></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBOW Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Small window</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first operation to perform is the construction of a model. </br>\n",
    "Inside the model, some parameters can be specified. For instance, we will work only with:\n",
    "- <i>window</i>: defines the window size;\n",
    "- <i>min_count</i>: defines the minnimum length of sentences to be considered;\n",
    "- <i>workers</i>: defines the CPU cores that will compute calculations for the model (my CPU has 8 cores, if you have a CPU with less cores, please modify this value);\n",
    "- <i>sg</i>: can assume the value of 1 or 0 (the default value), if its value is 1, then it will use skip grams to train the model, if the value is 0 it will train the model on a CBOW approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=3,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=3,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consists in building <i>vocabularies</i>, that is a collection of all the single tokens for each one of our models.</br>\n",
    "In order to build vocabularies we will use the <span style=\"color:#89FC00\">build_vocab()</span> method, provided by Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sw_cbow_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sw_cbow_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Medium window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=6,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=6,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mw_cbow_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mw_cbow_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Large window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=9,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lw_cbow_model = gensim.models.Word2Vec(\n",
    "    window=9,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lw_cbow_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lw_cbow_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip Gram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Small window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sw_skip_model = gensim.models.Word2Vec(\n",
    "    window=3,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sw_skip_model = gensim.models.Word2Vec(\n",
    "    window=3,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sw_skip_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sw_skip_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Medium window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mw_skip_model = gensim.models.Word2Vec(\n",
    "    window=6,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mw_skip_model = gensim.models.Word2Vec(\n",
    "    window=6,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mw_skip_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mw_skip_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Large window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lw_skip_model = gensim.models.Word2Vec(\n",
    "    window=9,\n",
    "    min_count=2, # This parameter do not consider sentences with \"x\" words or less, where x is the integer value specified\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lw_skip_model = gensim.models.Word2Vec(\n",
    "    window=9,\n",
    "    min_count=2,\n",
    "    workers=8, #This parameter is intended for CPU cores, if you have a CPU with less than 8 cores please modify the value\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lw_skip_model.build_vocab(f_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lw_skip_model.build_vocab(m_tokens, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consists on training the different groups of models that we have built. We will do it thanks to the Gensim <span style=\"color:#89FC00\">.train()</span> method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Small window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6226776, 7220155)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sw_cbow_model.train(f_tokens, total_examples=f_sw_cbow_model.corpus_count, epochs=f_sw_cbow_model.epochs)\n",
    "m_sw_cbow_model.train(m_tokens, total_examples=m_sw_cbow_model.corpus_count, epochs=m_sw_cbow_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6225343, 7220155)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sw_skip_model.train(f_tokens, total_examples=f_sw_skip_model.corpus_count, epochs=f_sw_skip_model.epochs)\n",
    "m_sw_skip_model.train(m_tokens, total_examples=m_sw_skip_model.corpus_count, epochs=m_sw_skip_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Medium window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6226185, 7220155)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mw_cbow_model.train(f_tokens, total_examples=f_mw_cbow_model.corpus_count, epochs=f_mw_cbow_model.epochs)\n",
    "m_mw_cbow_model.train(m_tokens, total_examples=m_mw_cbow_model.corpus_count, epochs=m_mw_cbow_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6226273, 7220155)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mw_skip_model.train(f_tokens, total_examples=f_mw_skip_model.corpus_count, epochs=f_mw_skip_model.epochs)\n",
    "m_mw_skip_model.train(m_tokens, total_examples=m_mw_skip_model.corpus_count, epochs=m_mw_skip_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Large window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6225367, 7220155)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lw_cbow_model.train(f_tokens, total_examples=f_lw_cbow_model.corpus_count, epochs=f_lw_cbow_model.epochs)\n",
    "m_lw_cbow_model.train(m_tokens, total_examples=m_lw_cbow_model.corpus_count, epochs=m_lw_cbow_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6227745, 7220155)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lw_skip_model.train(f_tokens, total_examples=f_lw_skip_model.corpus_count, epochs=f_lw_skip_model.epochs)\n",
    "m_lw_skip_model.train(m_tokens, total_examples=m_lw_skip_model.corpus_count, epochs=m_lw_skip_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Small window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pony', 0.8841539621353149),\n",
       " ('sailor', 0.8484433889389038),\n",
       " ('pawnshop', 0.8472279906272888),\n",
       " ('witch', 0.8382288217544556),\n",
       " ('ticket', 0.828952431678772),\n",
       " ('rat', 0.827035665512085),\n",
       " ('funny', 0.8247242569923401),\n",
       " ('stride', 0.8243754506111145),\n",
       " ('hump', 0.8238370418548584),\n",
       " ('locket', 0.8225745558738708)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rabbit', 0.7644575238227844),\n",
       " ('snake', 0.7404806613922119),\n",
       " ('mouse', 0.7385162711143494),\n",
       " ('duck', 0.7225423455238342),\n",
       " ('dog', 0.6943410634994507),\n",
       " ('tiger', 0.6769894957542419),\n",
       " ('weasel', 0.6688323616981506),\n",
       " ('frog', 0.6562343239784241),\n",
       " ('bird', 0.6529768705368042),\n",
       " ('madman', 0.6491336822509766)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mare', 0.7182251811027527),\n",
       " ('charger', 0.6970164775848389),\n",
       " (\"'who\", 0.6866154670715332),\n",
       " ('mask', 0.6820776462554932),\n",
       " ('tugged', 0.6818537712097168),\n",
       " ('snout', 0.6755131483078003),\n",
       " ('gipsy', 0.6753441095352173),\n",
       " ('basil', 0.6703851819038391),\n",
       " ('billy', 0.6690394878387451),\n",
       " ('parenthesis', 0.6674005389213562)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sw_skip_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('frog', 0.7005339860916138),\n",
       " ('rabbit', 0.6855319738388062),\n",
       " ('mouse', 0.6796906590461731),\n",
       " ('weasel', 0.67022705078125),\n",
       " ('panther', 0.6669593453407288),\n",
       " ('gardener', 0.666776716709137),\n",
       " ('cheshire', 0.6644233465194702),\n",
       " ('madman', 0.6584529876708984),\n",
       " ('chuchundra', 0.656449019908905),\n",
       " ('porpoise', 0.6506761908531189)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sw_skip_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Medium window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('basil', 0.8505427837371826),\n",
       " ('pony', 0.8295732736587524),\n",
       " ('hump', 0.8141831755638123),\n",
       " ('carp', 0.8107138872146606),\n",
       " (\"m'swyne\", 0.8095114827156067),\n",
       " ('mustache', 0.8079072833061218),\n",
       " ('scotchwoman', 0.8060427308082581),\n",
       " ('cripple', 0.8038398027420044),\n",
       " ('tombstone', 0.8025147914886475),\n",
       " ('locket', 0.802374005317688)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.7959019541740417),\n",
       " ('rabbit', 0.706752598285675),\n",
       " ('bird', 0.7050092220306396),\n",
       " ('hoarse', 0.6649045944213867),\n",
       " ('duchess', 0.6546960473060608),\n",
       " ('gluck', 0.6543200612068176),\n",
       " ('sigh', 0.6348352432250977),\n",
       " ('una', 0.6316945552825928),\n",
       " ('dog', 0.6301178932189941),\n",
       " ('madman', 0.6276779174804688)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_mw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'n'\", 0.6549415588378906),\n",
       " ('snout', 0.6533805727958679),\n",
       " ('puppy', 0.6421769857406616),\n",
       " ('basil', 0.6416086554527283),\n",
       " ('magpie', 0.638731062412262),\n",
       " ('hostler', 0.6283052563667297),\n",
       " ('quicker', 0.6271837949752808),\n",
       " (\"'who\", 0.6242798566818237),\n",
       " ('bitten', 0.623835027217865),\n",
       " ('squeaking', 0.6227161288261414)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mw_skip_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.6640286445617676),\n",
       " ('cheshire', 0.6524803042411804),\n",
       " ('parrot', 0.6407116651535034),\n",
       " ('buzzy', 0.634723961353302),\n",
       " ('weasel', 0.6270034313201904),\n",
       " ('pummy', 0.6223182082176208),\n",
       " ('panther', 0.6167601346969604),\n",
       " ('barked', 0.6111574172973633),\n",
       " ('chuchundra', 0.6072313189506531),\n",
       " ('terrier', 0.6021856665611267)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_mw_skip_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:#EE6352\">Large window</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gemman', 0.8393821120262146),\n",
       " ('suspiciously', 0.8381377458572388),\n",
       " ('sigh', 0.833740234375),\n",
       " ('mustache', 0.8319226503372192),\n",
       " ('pining', 0.829613208770752),\n",
       " ('witch', 0.8292569518089294),\n",
       " ('twinkle', 0.8275833129882812),\n",
       " ('encampment', 0.8221360445022583),\n",
       " ('pony', 0.8209250569343567),\n",
       " ('sharply', 0.8182221055030823)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.7600972056388855),\n",
       " ('rabbit', 0.7179290652275085),\n",
       " ('sigh', 0.6581215858459473),\n",
       " ('lobster', 0.6536357402801514),\n",
       " ('una', 0.6477910876274109),\n",
       " ('frog', 0.6341004371643066),\n",
       " ('remorsefully', 0.6334105730056763),\n",
       " ('madman', 0.6331332921981812),\n",
       " ('gluck', 0.6304264068603516),\n",
       " ('dog', 0.6173111200332642)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_lw_cbow_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('puppy', 0.6028403639793396),\n",
       " ('purring', 0.5921505093574524),\n",
       " ('puss', 0.5890118479728699),\n",
       " ('snout', 0.5772577524185181),\n",
       " ('tiger', 0.5758661031723022),\n",
       " ('mouse', 0.5753436088562012),\n",
       " ('pheasant', 0.573943555355072),\n",
       " ('hurrah', 0.5694153904914856),\n",
       " ('squeaking', 0.5672130584716797),\n",
       " ('worries', 0.5607874989509583)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lw_skip_model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cheshire', 0.7050946950912476),\n",
       " ('barked', 0.6400287747383118),\n",
       " ('parrot', 0.6369614005088806),\n",
       " ('buzzy', 0.6364743709564209),\n",
       " ('purr', 0.6242054104804993),\n",
       " ('mew', 0.6205807328224182),\n",
       " ('mouse', 0.6187389492988586),\n",
       " ('frog', 0.6104247570037842),\n",
       " ('snarl', 0.6101961135864258),\n",
       " ('raving', 0.6100438237190247)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_lw_skip_model.wv.most_similar(\"cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
